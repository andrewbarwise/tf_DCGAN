{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\n",
      "File \u001b[1;32mC:\\data\\tf_DCGAN\\.venv\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\data\\tf_DCGAN\\.venv\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32mC:\\data\\tf_DCGAN\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mC:\\data\\tf_DCGAN\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:123\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterator_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckpointInputPipelineHook\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterator_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_saveable_from_iterator\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlookup_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetInitializer\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlookup_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m index_table_from_dataset\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlookup_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m table_from_dataset\n",
      "File \u001b[1;32mC:\\data\\tf_DCGAN\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\lookup_ops.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_spec\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lookup_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m math_ops\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n",
      "File \u001b[1;32mC:\\data\\tf_DCGAN\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:2416\u001b[0m\n\u001b[0;32m   2410\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mresource_handle):\n\u001b[0;32m   2411\u001b[0m           \u001b[38;5;28;01mreturn\u001b[39;00m gen_lookup_ops\u001b[38;5;241m.\u001b[39mlookup_table_import_v2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mresource_handle,\n\u001b[0;32m   2412\u001b[0m                                                        restored_tensors[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   2413\u001b[0m                                                        restored_tensors[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m-> 2416\u001b[0m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNotDifferentiable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLookupTableFind\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2417\u001b[0m ops\u001b[38;5;241m.\u001b[39mNotDifferentiable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLookupTableFindV2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2418\u001b[0m ops\u001b[38;5;241m.\u001b[39mNotDifferentiable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLookupTableInsert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\data\\tf_DCGAN\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2863\u001b[0m, in \u001b[0;36mno_gradient\u001b[1;34m(op_type)\u001b[0m\n\u001b[0;32m   2861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op_type, six\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[0;32m   2862\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop_type must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2863\u001b[0m \u001b[43mgradient_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\data\\tf_DCGAN\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py:65\u001b[0m, in \u001b[0;36mRegistry.register\u001b[1;34m(self, candidate, name)\u001b[0m\n\u001b[0;32m     62\u001b[0m logging\u001b[38;5;241m.\u001b[39mvlog(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistering \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, candidate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# stack trace is [this_function, Register(), user_function,...]\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# so the user function is #2.\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m stack_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(stack) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stack_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\data\\Python\\lib\\traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mC:\\data\\Python\\lib\\traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mC:\\data\\Python\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE DATASET, PREPARE THE DATASET\n",
    "\n",
    "use the mnist dataset to train the generator and the discriminator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "\n",
    "# normalize the images to the range [-1, 1]\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256 \n",
    "\n",
    "# batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE THE GENERATOR\n",
    "\n",
    "this generator will use Conv2DTranspose (upsampling) layers to produce an image from random noise.\n",
    "\n",
    "start with a dense layer that takes a seed as input, then upsample several times until the desired image size of 28 * 28 *1\n",
    "\n",
    "important to note the activation function for each layer is 'leakyRelU' whilst in the layer it is \"tanh\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7,7,256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2f485fe7520>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the generator to create an image\n",
    "\n",
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training = False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE THE DISCRIMINATOR\n",
    "\n",
    "the discriminator is a CNN image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5,5), strides = (2, 2), padding = 'same', input_shape = [28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides = (2, 2), padding = 'same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the discriminator ( as yet untrained) to classify the generated image as real or fake.\n",
    "\n",
    "the model will be trained to return positive values for real images and negative values for fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00069675]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE LOSS AND OPTIMIZERS\n",
    "\n",
    "define loss functions and optimizers for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator loss, this method quantifies how well the discriminator is able to distinguish real imges from fake images.\n",
    "\n",
    "# it compares the discriminators predictions on real images to an array of one's and the discrimintors\n",
    "# predictions on fake (generated images) to an array of zero's\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator loss, this will quantify how well the generator tricks the discriminator.\n",
    "\n",
    "# if the generator is performing well, the discriminator will classify the fake images as real (or 1).\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the generator and discriminator optimizers are different since you train two networks separately\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoints\n",
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n",
    "                                    discriminator_optimizer = discriminator_optimizer,\n",
    "                                    generator = generator,\n",
    "                                    discriminator = discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE TRAINING LOOP\n",
    "\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the training loop begins with a generator receiving a random seed as input. that seed is used to produce an image. \n",
    "\n",
    "the discriminator is then used to classify real images (drawn from the training set) and fake images (produced by the generator.)\n",
    "\n",
    "the loss is calculated for each of these model sand the gradients are used to update the generator and discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(images):\n\u001b[0;32m      3\u001b[0m     noise \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([BATCH_SIZE, noise_dim])\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m gen_tape, tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m disc_tape:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training = True)\n",
    "        fake_output = discriminator(generated_images, training = True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "554b55162fcdb48176e3e8d35c51329582a028cdf76cf94e7a51245439188bb8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
